<?xml version="1.0" encoding="UTF-8"?>
<feed xmlns="http://www.w3.org/2005/Atom" xmlns:dc="http://purl.org/dc/elements/1.1/"><title>JBoss Tools Aggregated Feed</title><link rel="alternate" href="http://tools.jboss.org" /><subtitle>JBoss Tools Aggregated Feed</subtitle><dc:creator>JBoss Tools</dc:creator><entry><title>Secure Kubernetes certificates with cert-manager and Dekorate</title><link rel="alternate" href="https://developers.redhat.com/articles/2022/07/19/secure-kubernetes-certificates-cert-manager-and-dekorate" /><author><name>Jose Carvajal Hilario, Ana-Maria Mihalceanu, Charles Moulliard</name></author><id>6a78a218-d650-4212-b182-8982603d1964</id><updated>2022-07-19T07:00:00Z</updated><published>2022-07-19T07:00:00Z</published><summary type="html">&lt;p&gt;&lt;a href="https://cert-manager.io/"&gt;Cert-manager&lt;/a&gt; is a cloud-native certificate management service for &lt;a href="https://developers.redhat.com/topics/kubernetes"&gt;Kubernetes&lt;/a&gt; and &lt;a href="https://developers.redhat.com/openshift"&gt;Red Hat OpenShift&lt;/a&gt;. To configure cert-manager, you need to install several resources using custom resource definitions (CRDs). Depending on the issuer type and the certificate you need, creating these custom resources can become complex. This article introduces &lt;a href="https://dekorate.io/"&gt;Dekorate&lt;/a&gt; as an easier way to generate the cert-manager custom resources. We will also provide an example &lt;a href="https://developers.redhat.com/topics/enterprise-java"&gt;Java&lt;/a&gt; application based on &lt;a href="https://developers.redhat.com/topics/spring-boot"&gt;Spring Boot&lt;/a&gt; that uses the certificate generated by cert-manager.&lt;/p&gt; &lt;h2&gt;Getting started with the Dekorate cert-manager extension&lt;/h2&gt; &lt;p&gt;Cert-manager requires the installation of several resources, including &lt;code&gt;Issuer&lt;/code&gt;, &lt;code&gt;ClusterIssuer&lt;/code&gt;, and &lt;code&gt;Certificate&lt;/code&gt;. Cert-manager processes these resources to populate a secret, containing authentication information, such as a CA certificate, private key, server certificate, or Java keystores. This secret can then be used to secure your application endpoints or &lt;a href="https://kubernetes.io/docs/concepts/services-networking/ingress/"&gt;Kubernetes Ingress&lt;/a&gt; resources.&lt;/p&gt; &lt;p&gt;Dekorate, starting with version 2.10, can generate the certificate and issuer resources for you. Include the cert-manager Dekorate dependency in your POM file using the latest version of Dekorate from &lt;a href="https://search.maven.org/search?q=a:certmanager-annotations%20AND%20g:io.dekorate"&gt;Maven central&lt;/a&gt; as follows:&lt;/p&gt; &lt;pre&gt;&lt;code class="xml"&gt;&lt;dependency&gt; &lt;groupId&gt;io.dekorate&lt;/groupId&gt; &lt;artifactId&gt;certmanager-annotations&lt;/artifactId&gt; &lt;version&gt;{dekorate.version}&lt;/version&gt; &lt;/dependency&gt; &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The minimal information Dekorate needs for certificate configuration is:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;A &lt;code&gt;secretName&lt;/code&gt; property containing the name of the &lt;a href="https://kubernetes.io/docs/concepts/configuration/secret/"&gt;Kubernetes secret&lt;/a&gt; resource that will include the files generated by cert-manager.&lt;/li&gt; &lt;li&gt;The &lt;code&gt;Issuer&lt;/code&gt; that represents the certificate authority (CA). The &lt;a href="https://dekorate.io/docs/cert-manager#issuers"&gt;Issuer section of the Dekorate documentation &lt;/a&gt; lists supported options.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;You can start with a minimal configuration in the &lt;code&gt;.properties&lt;/code&gt; file and set up the following keys:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;dekorate.certificate.secret-name=tls-secret # The self-signed issuer: dekorate.certificate.self-signed.enabled=true &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The &lt;a href="https://dekorate.io/configuration-guide/#cert-manager"&gt;Dekorate Cert-Manager Configuration Guide&lt;/a&gt; lists many configuration options that determine how Dekorate works with cert-manager. You can specify configuration options by adding the &lt;code&gt;@Certificate&lt;/code&gt; annotation to your Java program:&lt;/p&gt; &lt;pre&gt;&lt;code class="java"&gt;@Certificate(secretName = "tls-secret", selfSigned = @SelfSigned(enabled = true)) public class Main { // ... } &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;This configuration generates all the resources in the &lt;code&gt;target/classes/dekorate/kubernetes.yml&lt;/code&gt; file, which should look like this:&lt;/p&gt; &lt;pre&gt;&lt;code class="yaml"&gt;--- apiVersion: cert-manager.io/v1 kind: Issuer metadata: name: kubernetes-example spec: selfSigned: {} --- apiVersion: cert-manager.io/v1 kind: Certificate metadata: name: kubernetes-example spec: encodeUsagesInRequest: false isCA: false issuerRef: name: kubernetes-example secretName: tls-secret &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The Dekorate cert-manager extension considers the secret that contains the files generated by cert-manager and mounts it as a volume and as part of the deployment. Dekorate allows the application to access the files and configure the HTTPS/TLS endpoint:&lt;/p&gt; &lt;pre&gt;&lt;code class="yaml"&gt;--- apiVersion: apps/v1 kind: Deployment metadata: name: kubernetes-example spec: replicas: 1 template: spec: containers: - name: kubernetes-example volumeMounts: - mountPath: /etc/certs name: volume-certs readOnly: true volumes: - name: volume-certs secret: optional: false secretName: tls-secret &lt;/code&gt;&lt;/pre&gt; &lt;h3&gt;Securing resources&lt;/h3&gt; &lt;p&gt;When securing your resources, it's important to validate that the requests are coming from known hosts. To add these trusted hosts, use the &lt;code&gt;dnsNames&lt;/code&gt; property for the certificate configuration. The following line, for example, adds a single hostname to the property:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;dekorate.certificate.dnsNames=foo.bar.com &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The certificate will then allow only requests for the &lt;code&gt;foo.bar.com&lt;/code&gt; server host. Add multiple hosts by separating them with commas.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: If the DNS hostname does not exist, you will get an error.&lt;/p&gt; &lt;p&gt;In Kubernetes, you can publicly expose an application using Ingress resources, such as:&lt;/p&gt; &lt;pre&gt;&lt;code class="yaml"&gt;apiVersion: networking.k8s.io/v1 kind: Ingress metadata: name: kubernetes-example spec: rules: - host: foo.bar.com http: paths: - pathType: Prefix path: "/" backend: service: name: kubernetes-example port: number: 8080 tls: - hosts: - foo.bar.com secretName: tls-secret # &lt; cert-manager will store the created certificate in this secret. &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Dekorate can help you generate the previous Ingress resource definition by adding the following key properties:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;dekorate.kubernetes.ingress.host=foo.bar.com dekorate.kubernetes.ingress.expose=true dekorate.kubernetes.ingress.tlsSecretName=tls-secret &lt;/code&gt;&lt;/pre&gt; &lt;h2&gt;Configuring HTTPS/TLS with Dekorate cert-manager extension for a Spring Boot application&lt;/h2&gt; &lt;p&gt;The example in this section demonstrates how to configure an HTTPS/TLS microservice using the Dekorate cert-manager extension.&lt;/p&gt; &lt;h3&gt;Enabling HTTPS transport&lt;/h3&gt; &lt;p&gt;To enable the HTTPS/TLS transport in Spring Boot, add the following properties:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;server.port=8443 server.ssl.enabled=true &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Next, configure the Java PKCS#12 keystore properties that your Spring Boot application will use to get the server certificate signed and obtain the private key:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;server.ssl.key-store-type=PKCS12 server.ssl.key-store=/path/to/keystore.p12 server.ssl.key-store-password=the password &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Since the keystore file is password protected, you need to create the secret that contains that password. This is where cert-manager comes into play. The following sections illustrate how to instruct cert-manager to generate the keystore and how to configure the application to mount and use the secret.&lt;/p&gt; &lt;h3&gt;Generating a self-signed certificate and keystore&lt;/h3&gt; &lt;p&gt;You can configure the Dekorate cert-manager extension to request the generation of the &lt;code&gt;keystore.p12&lt;/code&gt; PKCS#12 file and a self-signed certificate by specifying:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;dekorate.certificate.secret-name=tls-secret dekorate.certificate.self-signed.enabled=true dekorate.certificate.keystores.pkcs12.create=true # the secret name of the password: dekorate.certificate.keystores.pkcs12.passwordSecretRef.name=pkcs12-pass dekorate.certificate.keystores.pkcs12.passwordSecretRef.key=password &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Based on this configuration, Dekorate will create the &lt;code&gt;Certificate&lt;/code&gt; and &lt;code&gt;Issuer&lt;/code&gt; resources that you can install in Kubernetes. This resource will be used by the Certificate Manager to generate a self-signed certificate and the keystore files within a secret named &lt;code&gt;tls-secret&lt;/code&gt;.&lt;/p&gt; &lt;p&gt;To protect the keystore, create a secret named &lt;code&gt;pkcs12-pass&lt;/code&gt; in the &lt;code&gt;src/main/resources/k8s/common.yml&lt;/code&gt; file. The data field must include the key password which is encoded in base64. The following example, shows the "supersecret" string encoded in base64:&lt;/p&gt; &lt;pre&gt;&lt;code class="yaml"&gt;--- apiVersion: v1 kind: Secret metadata: name: pkcs12-pass data: # "supersecret" in base64: password: c3VwZXJzZWNyZXQ= type: Opaque &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;You can instruct Dekorate to find the &lt;code&gt;common.yml&lt;/code&gt; under &lt;code&gt;src/main/resources/&lt;/code&gt; by setting the folder name (eg. &lt;code&gt;k8s&lt;/code&gt;) in the &lt;code&gt;dekorate.options.input-path&lt;/code&gt; property:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;dekorate.options.input-path=k8s &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;After configuring these details and installing the resources created by Dekorate on the Kubernetes platform, cert-manager will generate the generated PKCS#12 keystore file named &lt;code&gt;keystore.p12&lt;/code&gt; within the &lt;code&gt;tls-secret&lt;/code&gt; secret.&lt;/p&gt; &lt;p&gt;The Dekorate cert-manager extension will also configure the Spring Boot application to automatically mount a volume using the &lt;code&gt;tls-secret&lt;/code&gt; secret at the path &lt;code&gt;/etc/certs&lt;/code&gt; (the path can be specified using the &lt;code&gt;dekorate.certificate.volume-mount-path&lt;/code&gt; property). Therefore, you can map the Keystore file and password into the &lt;code&gt;server.ssl.key-store&lt;/code&gt; and &lt;code&gt;server.ssl.key-store-password&lt;/code&gt; Spring Boot properties:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;dekorate.kubernetes.env-vars[0].name=SERVER_SSL_KEY_STORE dekorate.kubernetes.env-vars[0].value=/etc/certs/keystore.p12 dekorate.kubernetes.env-vars[1].name=SERVER_SSL_KEY_STORE_PASSWORD dekorate.kubernetes.env-vars[1].secret=pkcs12-pass dekorate.kubernetes.env-vars[1].value=password &lt;/code&gt;&lt;/pre&gt; &lt;h3&gt;Running the application in Kubernetes&lt;/h3&gt; &lt;p&gt;To run this example, you must have access to a Kubernetes cluster and &lt;a href="https://cert-manager.io/docs/installation/"&gt;install cert-manager&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;Next, generate the manifests and push the application container image to your container registry. This example uses &lt;a href="https://quay.io"&gt;Quay.io&lt;/a&gt; as the container registry and &lt;code&gt;user&lt;/code&gt; as the group name, but you should substitute the values from your environment:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;mvn clean install -Ddekorate.push=true -Ddekorate.docker.registry=quay.io -Ddekorate.docker.group=user &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;After you execute the previous command, install the generated manifests, which are available at &lt;code&gt;target/classes/META-INF/dekorate/kubernetes.yml&lt;/code&gt;:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;kubectl apply -f target/classes/META-INF/dekorate/kubernetes.yml &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;After a few moments, check for the secret resource named &lt;code&gt;tls-secret&lt;/code&gt; created by the &lt;code&gt;Cert-Manager&lt;/code&gt; in the form of a PKCS#12 keystore file:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;kubectl get secret/tls-secret -o yaml | grep keystore.p12 &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Check the status of your pods using the command:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;kubectl get pods -w &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;If your application is running, the output looks like this:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;NAME READY STATUS RESTARTS AGE spring-boot-with-certmanager-example-566546987c-nj94n 1/1 Running 0 2m23s &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Try out the application by port-forwarding port 8443:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;kubectl port-forward spring-boot-with-certmanager-example-566546987c-nj94n 8443:8443 &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Now if you browse to &lt;code&gt;https://localhost:8443/&lt;/code&gt;, you should see &lt;code&gt;Hello world from HTTPS!&lt;/code&gt;&lt;/p&gt; &lt;h2&gt;Dekorate reduces the complexity of certification management&lt;/h2&gt; &lt;p&gt;In this article, you learned how to easily generate cert-manager custom resources using Dekorate, and how to use the generated secret by cert-manager for a Spring Boot application.&lt;/p&gt; The post &lt;a href="https://developers.redhat.com/articles/2022/07/19/secure-kubernetes-certificates-cert-manager-and-dekorate" title="Secure Kubernetes certificates with cert-manager and Dekorate"&gt;Secure Kubernetes certificates with cert-manager and Dekorate&lt;/a&gt; appeared first on &lt;a href="https://developers.redhat.com/blog" title="Red Hat Developer"&gt;Red Hat Developer&lt;/a&gt;. &lt;br /&gt;&lt;br /&gt;</summary><dc:creator>Jose Carvajal Hilario, Ana-Maria Mihalceanu, Charles Moulliard</dc:creator><dc:date>2022-07-19T07:00:00Z</dc:date></entry><entry><title type="html">Ask (Quark)us anything!</title><link rel="alternate" href="https://quarkus.io/blog/quarkus-insights-qanda4/" /><author><name>Max Rydahl Andersen</name></author><id>https://quarkus.io/blog/quarkus-insights-qanda4/</id><updated>2022-07-19T00:00:00Z</updated><content type="html">Our fourth semi-annually Q&amp;amp;A session is happening. We meant to do it this week but a case of covid made us take a small break! Instead we will do it on the coming Monday. To submit questions comment on this blog or the matching post in our GitHub Discussion forum...</content><dc:creator>Max Rydahl Andersen</dc:creator></entry><entry><title type="html">Kogito Serverless Workflow GitHub Extension released!</title><link rel="alternate" href="https://blog.kie.org/2022/07/new-github-extension-released.html" /><author><name>Ajay Jaganathan</name></author><id>https://blog.kie.org/2022/07/new-github-extension-released.html</id><updated>2022-07-18T12:06:21Z</updated><content type="html">We are very happy to announce the release of our Kogito Serverless Workflow Editor for GitHub extension in the . HOW TO INSTALL THE EXTENSION? A prerequisite is to have installed. You can install the extension in two ways: 1. Go to the and click on the Add to Chrome. 2. Go to the page, download and extract the chrome_extension_serverless_workflow_editor_VERSION.zip. Then in Google Chrome go to Customize and control → Settings → Extensions → Load unpacked and open the dist folder. WHAT DOES THE EXTENSION DO? You can use the Serverless Workflow editor to edit the  files in the code editor and view the Serverless Workflow diagram in the diagram visualizer. WHAT ARE ITS FEATURES? * Dynamically updates the diagram as you edit the code. * Saves the workflow diagram as .svg file in the workspace. * Auto-completes the code based on context. * Validates the code to provide an error free experience. Here is a quick video of the extension at work: Working with the Kogito Serverless Workflow Editor for GitHub extension For more information on the extension, take a look at our awesome ! Please do let us know your feedback so that we can continue improving the extension. Thanks to all the awesome engineers who helped us to achieve this!! Stay tuned to get more updates on the extension! The post appeared first on .</content><dc:creator>Ajay Jaganathan</dc:creator></entry><entry><title>How OpenShift service contexts simplify client connections</title><link rel="alternate" href="https://developers.redhat.com/articles/2022/07/18/simplify-client-connection-configurations-service-contexts" /><author><name>Ramakrishna Pattnaik, John Byrne</name></author><id>18f84491-1c55-4d59-b93b-acd4ebc36a4a</id><updated>2022-07-18T07:00:00Z</updated><published>2022-07-18T07:00:00Z</published><summary type="html">&lt;p&gt;The latest release of &lt;code&gt;rhoas&lt;/code&gt;, the command-line interface (CLI) for &lt;a href="https://www.redhat.com/en/technologies/cloud-computing/openshift/application-services"&gt;Red Hat OpenShift application services&lt;/a&gt;, adds a powerful and flexible feature called &lt;em&gt;service contexts&lt;/em&gt; that makes it easier than ever to connect clients to your instances of OpenShift application services. This article illustrates this new feature and shows how it can accelerate your development workflows for stream-based applications.&lt;/p&gt; &lt;h2&gt;Service contexts facilitate client connections&lt;/h2&gt; &lt;p&gt;Red Hat OpenShift application services, such as &lt;a href="https://developers.redhat.com/products/red-hat-openshift-streams-for-apache-kafka/overview"&gt;Red Hat OpenShift Streams for Apache Kafka&lt;/a&gt; and &lt;a href="https://developers.redhat.com/articles/2021/10/11/get-started-openshift-service-registry"&gt;Red Hat OpenShift Service Registry&lt;/a&gt;, are managed cloud services that provide a streamlined developer experience for building, deploying, and scaling real-time applications in hybrid-cloud environments.&lt;/p&gt; &lt;p&gt;The OpenShift application services CLI is a rich command-line interface for managing application services. With the new service contexts feature, you can use the CLI to define sets of service instances for specific use cases, projects, or environments, as indicated in Figure 1. After you define a context, a single command can generate the connection configuration information required by client applications.&lt;/p&gt; &lt;figure role="group"&gt; &lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content-full-width"&gt; &lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/or7yZYHBGpMmn7LbheiBZLYrewKSH4MATwjQk3Nk4Qy8GRgOPCiSGyyBmSSoeth0c3QVoSpZvGC9yImaApEKImBWey8brZzo-oB_7qUe7vs9fEiLNQ-ikKfRleFb5GxMoGJrTbta4hoG_jb1qg.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_full_width_1440px_w/public/or7yZYHBGpMmn7LbheiBZLYrewKSH4MATwjQk3Nk4Qy8GRgOPCiSGyyBmSSoeth0c3QVoSpZvGC9yImaApEKImBWey8brZzo-oB_7qUe7vs9fEiLNQ-ikKfRleFb5GxMoGJrTbta4hoG_jb1qg.png?itok=wlDu6yv2" width="1440" height="1057" alt="A context represents a collection of services dedicated to a particular purpose." loading="lazy" typeof="Image" /&gt; &lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 1: A context represents a collection of services dedicated to a particular purpose. &lt;/div&gt; &lt;/div&gt; &lt;/article&gt; &lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;&lt;/figcaption&gt; &lt;/figure&gt; &lt;p&gt;Thus, service contexts enable you to switch easily between defined sets of service instances and to quickly and reliably generate connection configurations for those instances. This process represents a significant improvement over time-consuming and error-prone workflows that require you to create individual configuration files for standalone service instances and applications in different languages.&lt;/p&gt; &lt;p&gt;This article shows where service contexts excel and why we're excited to introduce this feature.&lt;/p&gt; &lt;p&gt;First, we'll walk through a practical example that uses service contexts to connect a local client application to some instances in OpenShift application services. Then we'll look at how to use contexts with OpenShift-based applications and how to share contexts with other team members.&lt;/p&gt; &lt;h2&gt;Connect a Quarkus application to OpenShift application services&lt;/h2&gt; &lt;p&gt;This example uses service contexts to connect an example &lt;a href="https://developers.redhat.com/products/quarkus/overview"&gt;Quarkus&lt;/a&gt; application to some Kafka and Service Registry instances in OpenShift application services. The Quarkus application produces a stream of quotes (actually randomly generated strings of characters) and displays them on a web page.&lt;/p&gt; &lt;p&gt;First, create a brand new service context:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-html"&gt;$ rhoas context create --name quotes-dev&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The context you just created becomes the &lt;em&gt;current&lt;/em&gt; context. You can create multiple contexts, putting different services in each one, and offering contexts to different developers to give them access to sets of services.&lt;/p&gt; &lt;p&gt;Next, create some Kafka and Service Registry instances in the current context:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-html"&gt;$ rhoas kafka create --name example-kafka-instance --wait $ rhoas service-registry create --name example-registry-instance&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The new Kafka and Service Registry instances are automatically added to the current context. You could also add existing Kafka and Service Registry instances to the current context using the &lt;a href="https://access.redhat.com/documentation/en-us/red_hat_openshift_application_services/1/guide/8bd088a6-b7b7-4e5d-832a-b0f0494f9070#_ceac13a8-667d-4262-984c-adfce81e59dc"&gt;context set-kafka&lt;/a&gt; and &lt;a href="https://access.redhat.com/documentation/en-us/red_hat_openshift_application_services/1/guide/8bd088a6-b7b7-4e5d-832a-b0f0494f9070#_90ac4ba8-8ad8-4f30-b0bb-62e2391c5f41"&gt;context set-registry&lt;/a&gt; CLI commands.&lt;/p&gt; &lt;p&gt;Now clone a sample Quarkus application to run locally:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-html"&gt;$ git clone https://github.com/redhat-developer/app-services-guides.git $ cd app-services-guides/code-examples/quarkus-service-registry-quickstart/&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The sample Quarkus application has two components: A producer and a consumer. The producer generates a stream of quote messages to a Kafka topic. The consumer component consumes these messages and displays their strings on a web page.&lt;/p&gt; &lt;p&gt;The Quarkus application requires a Kafka topic called &lt;code&gt;quotes&lt;/code&gt; in your Kafka instance. Create the topic as follows:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-html"&gt;$ rhoas kafka topic create --name quotes&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;You already created a context for your Kafka and Service Registry instances, so you're ready to generate the configuration information required to connect the Quarkus application to these instances through a &lt;a href="https://access.redhat.com/documentation/en-us/red_hat_openshift_application_services/1/guide/8bd088a6-b7b7-4e5d-832a-b0f0494f9070#_604e7a08-2776-4bb4-b2ee-73c09b969d28"&gt;generate-config&lt;/a&gt; command:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-html"&gt;$ rhoas generate-config --type env --output-file ./producer/.env&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;All &lt;code&gt;rhoas&lt;/code&gt; commands are executed against all the service instances in the current context, so you didn't need to explicitly specify any instances in the previous command. This broad reach is an important characteristic of service contexts. The feature gives you the flexibility to quickly and seamlessly switch between large sets of service instances and run CLI commands against them.&lt;/p&gt; &lt;p&gt;The Quarkus application requires the connection configuration information for your context to be available to both the producer and the consumer. You previously generated the configuration in the producer directory, so you can simply copy the same &lt;code&gt;.env&lt;/code&gt; file to the consumer directory:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-html"&gt;$ cp ./producer/.env ./consumer/.env &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;For the context that you defined, the contents of the &lt;code&gt;.env&lt;/code&gt; file should look like the following:&lt;/p&gt; &lt;pre&gt; &lt;code class="java language-markdown"&gt;## Generated by rhoas cli ## Kafka Configuration KAFKA_HOST=test-insta-ca---q---mrrjobj---a.bf2.kafka.rhcloud.com:443 ## Service Registry Configuration SERVICE_REGISTRY_URL=https://bu98.serviceregistry.rhcloud.com/t/cc8a243a-feed-4a4c-9394-5a35ce83cca5 SERVICE_REGISTRY_CORE_PATH=/apis/registry/v2 SERVICE_REGISTRY_COMPAT_PATH=/apis/ccompat/v6 ## Authentication Configuration RHOAS_CLIENT_ID=srvc-acct-45038cc5-0eb1-496f-a678-24ca7ed0a7bd RHOAS_CLIENT_SECRET=001a40b1-9a63-4c70-beda-3447b64a7783 RHOAS_OAUTH_TOKEN_URL=https://identity.api.openshift.com/auth/realms/rhoas/protocol/openid-connect/token&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The &lt;code&gt;generate-config&lt;/code&gt; command created a service account (under the environment variable name &lt;code&gt;RHOAS_CLIENT_ID&lt;/code&gt;) to authenticate client applications with the Kafka and Service Registry instances in your context. To enable the service account to work with these instances, you need to grant the service account access to the instances:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-html"&gt;$ rhoas kafka acl grant-access --producer --consumer --service-account srvc-acct-45038cc5-0eb1-496f-a678-24ca7ed0a7bd --topic quotes --group all $ rhoas service-registry role add --role manager --service-account srvc-acct-45038cc5-0eb1-496f-a678-24ca7ed0a7bd &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;You previously made the &lt;code&gt;.env&lt;/code&gt; file available to both the producer and consumer components of the Quarkus application. Now use &lt;a href="https://maven.apache.org/"&gt;Apache Maven&lt;/a&gt; to run the producer component:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-html"&gt;$ cd producer $ mvn quarkus:dev&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The &lt;code&gt;producer&lt;/code&gt; component starts to generate quote messages to the dedicated &lt;code&gt;quotes&lt;/code&gt; topic in the Kafka instance.&lt;/p&gt; &lt;p&gt;The Quarkus application also created a schema artifact with an ID of &lt;code&gt;quotes-value&lt;/code&gt; in the Service Registry instance. The producer uses the schema artifact to validate that each message representing a quote conforms to a defined structure. To view the contents of the schema artifact created by the Quarkus application, run the following command:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-html"&gt;$ rhoas service-registry artifact get --artifact-id quotes-value&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The output is:&lt;/p&gt; &lt;pre&gt; &lt;code class="javascript language-markdown"&gt;{ "type": "record", "name": "Quote", "namespace": "org.acme.kafka.quarkus", "fields": [ { "name": "id", "type": { "type": "string", "avro.java.string": "String" } }, { "name": "price", "type": "int" } ] }&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Next, with the producer still running, use Apache Maven to run the consumer component:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-html"&gt;$ cd consumer $ mvn quarkus:dev&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The consumer component consumes the stream of quotes and displays them on your local web page at &lt;code&gt;http://localhost:8080/quotes.html&lt;/code&gt;. The consumer component also uses the &lt;code&gt;quotes-value&lt;/code&gt; schema artifact to validate that messages conform to the structure defined in the schema.&lt;/p&gt; &lt;p&gt;Figure 2 shows an example of the output displayed on the web page.&lt;/p&gt; &lt;figure role="group"&gt; &lt;figcaption class="rhd-c-caption"&gt;&lt;/figcaption&gt; &lt;/figure&gt; &lt;p&gt;This example has shown that, after you defined a context, connecting your client application to OpenShift application services was as easy as generating a single file for connection information and copying this file to the application.&lt;/p&gt; &lt;p&gt;In the final sections of this blog post, we'll look briefly at two other use cases: Using service contexts to connect applications in &lt;a href="https://developers.redhat.com/products/openshift"&gt;Red Hat OpenShift&lt;/a&gt;, and sharing service contexts with other team members.&lt;/p&gt; &lt;h2&gt;Using service contexts to connect OpenShift-based applications&lt;/h2&gt; &lt;p&gt;In the previous example, you generated a connection configuration as a set of environment variables, which is convenient for a client application running locally. But what if you're running a container-based application on OpenShift? Well, service contexts make that easy, too. In this situation, you can directly generate the connection configuration information as an OpenShift secret file:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-html"&gt;$ rhoas generate-config --type secret --output-file ./rhoas-services-secret.yaml&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;When you've generated a secret, you can store it securely using methods such as:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;A secret-management solution such as &lt;a href="https://www.vaultproject.io/"&gt;Hashicorp Vault&lt;/a&gt;&lt;/li&gt; &lt;li&gt;The &lt;a href="https://github.com/jkroepke/helm-secrets"&gt;helm-secrets&lt;/a&gt; plug-in&lt;/li&gt; &lt;li&gt;Encrypting and pushing the secret to a GitHub repository&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;You can apply the secret to an OpenShift project using a command like the following:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-html"&gt;$ oc apply -f ./rhoas-services-secret.yaml&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;When you've applied the secret to your OpenShift project, you can refer to the secret from various resources, including OpenShift application templates, &lt;a href="https://docs.openshift.com/container-platform/4.7/openshift_images/using_images/using-s21-images.html"&gt;Source-to-Image&lt;/a&gt; (S2I) builds, &lt;a href="https://helm.sh"&gt;Helm charts&lt;/a&gt;, and service binding configurations.&lt;/p&gt; &lt;h2&gt;Sharing service contexts&lt;/h2&gt; &lt;p&gt;To share a context with other team members, you just need to share the context's configuration file. For example, you can push the file to a shared GitHub repository as described in this section.&lt;/p&gt; &lt;p&gt;Don't confuse the context's configuration file with the &lt;code&gt;.env&lt;/code&gt; file of environment variables that you generated for connection information earlier in the article. Instead, the context file lists the service instances that are in the context. The file contains JSON and is stored locally on your computer. To get the path to the context file, run the following command:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-html"&gt;$ rhoas context status&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;When you have the path to the file, you can copy it to a location such as a local Git repository. An example for Linux follows:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-markdown"&gt;$ cp &lt;path-to-context-file&gt; ./profiles.json&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;To share the service context with other developers, commit and push the file to a shared working area such as the team's Git repository. It's safe to push context files even to public repositories because the files contain only identifiers for the service instances.&lt;/p&gt; &lt;p&gt;Now, suppose another team member wants to use the shared context. When that team member has the context file (they fetched it from the shared repository, for example), they must define an environment variable called &lt;code&gt;RHOAS_CONTEXT&lt;/code&gt; that points to the context file. An example for Linux follows:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-html"&gt;$ export RHOAS_CONTEXT=./profiles.json&lt;/code&gt;&lt;/pre&gt; &lt;h2&gt;Service contexts: Quick, safe, and scalable&lt;/h2&gt; &lt;p&gt;This article has shown how the new service contexts feature of the CLI greatly simplifies the job of connecting client applications to sets of service instances in Red Hat OpenShift application services. This powerful and flexible feature automates the work that you previously spent on manual, error-prone configuration tasks and enables your team to focus on what it does best: Developing great stream-based applications.&lt;/p&gt; &lt;p&gt;To learn how to get started with the OpenShift application services CLI and start benefiting from the service contexts feature, see our detailed documentation:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;a href="https://access.redhat.com/documentation/en-us/red_hat_openshift_application_services/1/guide/bb30ee92-9e0a-4fd6-a67f-aed8910d7da3"&gt;Installing and configuring the rhoas CLI&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://access.redhat.com/documentation/en-us/red_hat_openshift_streams_for_apache_kafka/1/guide/88e1487a-2a14-4b35-85b9-a7a2d67a37f3"&gt;Getting started with the rhoas CLI for Red Hat OpenShift Streams for Apache Kafka&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://access.redhat.com/documentation/en-us/red_hat_openshift_streams_for_apache_kafka/1/guide/2f4bf7cf-5de2-4254-8274-6bf71673f407"&gt;Managing account access in Red Hat OpenShift Streams for Apache Kafka&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://access.redhat.com/documentation/en-us/red_hat_openshift_service_registry/1/guide/7717db0b-9fad-4fff-91b7-b311b63290a4"&gt;Managing account access in Red Hat OpenShift Service Registry&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://access.redhat.com/documentation/en-us/red_hat_openshift_application_services/1/guide/8bd088a6-b7b7-4e5d-832a-b0f0494f9070#_b7f033ec-6f0c-4b3c-89b0-cb1801de19f9"&gt;The CLI command reference&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; The post &lt;a href="https://developers.redhat.com/articles/2022/07/18/simplify-client-connection-configurations-service-contexts" title="How OpenShift service contexts simplify client connections"&gt;How OpenShift service contexts simplify client connections&lt;/a&gt; appeared first on &lt;a href="https://developers.redhat.com/blog" title="Red Hat Developer"&gt;Red Hat Developer&lt;/a&gt;. &lt;br /&gt;&lt;br /&gt;</summary><dc:creator>Ramakrishna Pattnaik, John Byrne</dc:creator><dc:date>2022-07-18T07:00:00Z</dc:date></entry><entry><title>New HTTP clients, a Java generator, and more in Fabric8 6.0.0</title><link rel="alternate" href="https://developers.redhat.com/articles/2022/07/15/new-http-clients-java-generator-and-more-fabric8-600" /><author><name>Steven Hawkins</name></author><id>e55d475c-c178-4abc-8467-d9aeb7a0866f</id><updated>2022-07-15T07:00:00Z</updated><published>2022-07-15T07:00:00Z</published><summary type="html">&lt;p&gt;The &lt;a href="https://github.com/fabric8io/kubernetes-client"&gt;Fabric8&lt;/a&gt; Kubernetes client has been simplifying &lt;a href="https://developers.redhat.com/topics/enterprise-java"&gt;Java&lt;/a&gt; developers' use of &lt;a href="https://developers.redhat.com/topics/kubernetes"&gt;Kubernetes&lt;/a&gt; for several years. The 6.0.0 release represents a major body of work spanning about five months of effort in both the core of the project and in related utilities.&lt;/p&gt; &lt;p&gt;This article takes a look at new features and other important changes in the Fabric8 Kubernetes client, including:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;New HTTP clients&lt;/li&gt; &lt;li&gt;Java generator&lt;/li&gt; &lt;li&gt;Resource API&lt;/li&gt; &lt;li&gt;API refinements&lt;/li&gt; &lt;li&gt;Kubernetes testing improvements&lt;/li&gt; &lt;/ul&gt; &lt;h1&gt;How to get the new Fabric8 Java client&lt;/h1&gt; &lt;p&gt;You can find the most current Fabric8 Java client release on &lt;a href="https://search.maven.org/artifact/io.fabric8/kubernetes-client"&gt;Maven Central&lt;/a&gt;. To start using the new client, add it as a dependency in your Maven &lt;code&gt;pom.xml&lt;/code&gt; or Gradle build file. For Kubernetes, the dependency is:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;&lt;dependency&gt; &lt;groupId&gt;io.fabric8&lt;/groupId&gt; &lt;artifactId&gt;kubernetes-client&lt;/artifactId&gt; &lt;version&gt;6.0.0&lt;/version&gt; &lt;/dependency&gt; &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Or for &lt;a href="https://developers.redhat.com/products/openshift/overview"&gt;Red Hat OpenShift&lt;/a&gt;:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;&lt;dependency&gt; &lt;groupId&gt;io.fabric8&lt;/groupId&gt; &lt;artifactId&gt;openshift-client&lt;/artifactId&gt; &lt;version&gt;6.0.0&lt;/version&gt; &lt;/dependency&gt; &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The sections below on the new HTTP clients API refinements will help you understand the new choices you have in your Fabric8 client dependencies.&lt;/p&gt; &lt;p&gt;And for your future Fabric8 Kubernetes client needs, please use the snapshot releases being published to &lt;a href="https://github.com/fabric8io/kubernetes-client/discussions/4208#discussioncomment-2957095"&gt;Maven Central&lt;/a&gt;.&lt;/p&gt; &lt;h1&gt;New features&lt;/h1&gt; &lt;p&gt;The feature work of the Fabric8 client has been driven by a diverse set of needs with an eye towards compatibility and continuity for existing users. So while the &lt;a href="https://raw.githubusercontent.com/fabric8io/kubernetes-client/6.0/CHANGELOG.md"&gt;changelog&lt;/a&gt; and &lt;a href="https://raw.githubusercontent.com/fabric8io/kubernetes-client/6.0/doc/MIGRATION-v6.md"&gt;migration guide&lt;/a&gt; may be lengthy, we expect that your upgrade process will be mostly seamless.&lt;/p&gt; &lt;h2&gt;New HTTP clients&lt;/h2&gt; &lt;p&gt;With some refinements to the HTTP client API introduced in 5.x, we were able to create a &lt;a href="https://github.com/fabric8io/kubernetes-client/issues/3855"&gt;JDK&lt;/a&gt; and an &lt;a href="https://github.com/fabric8io/kubernetes-client/issues/4180"&gt;Eclipse Jetty&lt;/a&gt; client implementation. A &lt;a href="https://github.com/fabric8io/kubernetes-client/issues/2764"&gt;Vert.x client&lt;/a&gt; is still in the works.&lt;/p&gt; &lt;p&gt;This means you can choose the client that is best suited to your needs—which could be one that is already being used in your project. You won't be locked into additional &lt;code&gt;OkHttp&lt;/code&gt; dependencies unless you want to be.&lt;/p&gt; &lt;p&gt;Since the abstraction layer and alternative client implementations are new, please let us know if you encounter any issues with them. You should also check the repo for known issues with the respective implementation—the &lt;a href="https://github.com/fabric8io/kubernetes-client/tree/6.0/httpclient-jdk"&gt;JDK readme&lt;/a&gt;, for example.&lt;/p&gt; &lt;p&gt;The &lt;a href="https://raw.githubusercontent.com/fabric8io/kubernetes-client/6.0/doc/FAQ.md"&gt;FAQ&lt;/a&gt; covers how to configure your project for a given HTTP client, along with several other topics. In short, you should exclude the &lt;code&gt;kubernetes-httpclient-okhttp&lt;/code&gt; dependency and add a runtime dependency to the desired HTTP client: &lt;code&gt;kubernetes-httpclient-jetty&lt;/code&gt; or &lt;code&gt;kubernetes-httpclient-jdk&lt;/code&gt;.&lt;/p&gt; &lt;p&gt;If you need to customize the configuration of the client, you should add a compile time reference to the respective HTTP client—&lt;code&gt;kubernetes-httpclient-xxx&lt;/code&gt;—and extend its &lt;code&gt;HttpClient.Factory&lt;/code&gt;: &lt;code&gt;JettyHttpClientFactory&lt;/code&gt;, &lt;code&gt;JdkHttpClientFactory&lt;/code&gt;, and &lt;code&gt;OkHttpClientFactory&lt;/code&gt;.&lt;/p&gt; &lt;h2&gt;Java generator&lt;/h2&gt; &lt;p&gt;Kubernetes is still a world dominated by &lt;a href="https://developers.redhat.com/topics/go"&gt;Go&lt;/a&gt; tools and operators. When using the &lt;code&gt;kubernetes-client&lt;/code&gt;, you often have to deal with externally defined (and generated) Custom Resource Definitions (CRDs). So far, the &lt;a href="https://github.com/fabric8io/kubernetes-client/tree/6.0/extensions"&gt;extensions&lt;/a&gt; available for Fabric8 have partially closed the gap by offering typed Java representations for some common use cases. In the 6.x release, we are introducing a full blown Java generator capable of automatically extracting fully typed Java representations from arbitrary YAML/JSON CRDs. You can check some examples of the generated code &lt;a href="https://github.com/fabric8io/kubernetes-client/tree/6.0/java-generator/core/src/test/resources/io/fabric8/java/generator/approvals"&gt;here&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;The tool can generate Java classes annotated with &lt;code&gt;lombok&lt;/code&gt; and &lt;code&gt;sundrio&lt;/code&gt; annotations in order to provide a seamless &lt;a href="https://github.com/fabric8io/kubernetes-client/blob/b90ee77091e50826f1c21f3c518483a5299f77b9/java-generator/it/src/it/extensions/src/test/java/io/fabric8/it/extensions/camelk/JavaGeneratedCamelK.java#L32"&gt;API and user experience&lt;/a&gt; when using those.&lt;/p&gt; &lt;p&gt;Whether you want to &lt;a href="https://andreaperuffo.com/posts/java-shell-4-kube/"&gt;easily and quickly&lt;/a&gt; interact with Java code with an external CRD, or you want to go down the path of full contract first development in your Operator, the Java generator is the instrument you are looking for.&lt;/p&gt; &lt;p&gt;Eager to start? You can find detailed instructions on how to use it in the &lt;a href="https://github.com/fabric8io/kubernetes-client/blob/6.0/doc/java-generation-from-CRD.md"&gt;official documentation&lt;/a&gt;.&lt;/p&gt; &lt;h2&gt;Resource API&lt;/h2&gt; &lt;p&gt;Most operations are performed on a resource. The Fabric8 5.x APIs could make dealing with existing &lt;code&gt;KubernetesResource&lt;/code&gt; objects a little cumbersome when it came to obtaining the resource. It was quite common to do something like this:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;// obtain an existing configMap somehow ConfigMap configMap = ... ... Resource&lt;ConfigMap&gt; resource = client.configMaps().inNamespace(configMap.getMetadata().getNamespace()).withName(configMap.getMetadata().getName()); resource.delete(); // or some other operation &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;In 6.0, several issues have been addressed, including &lt;a href="https://github.com/fabric8io/kubernetes-client/issues/3407"&gt;#3407&lt;/a&gt; and &lt;a href="https://github.com/fabric8io/kubernetes-client/issues/3973"&gt;#3973&lt;/a&gt;, that make it possible to obtain the Resource directly:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;Resource&lt;ConfigMap&gt; resource = client.resource(configMap); // or used fluently client.resource(configMap).delete(); &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;There are other places to directly get resources. For instance, all of the following return a Stream&lt;Resource&gt;:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;client.configMaps().resources(); client.configMaps().withLabel("x").resources(); client.resourceList(...).resources(); &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Using any of these, you can implement composite operations easily with lambdas:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;client.secrets().resources().forEach(Resource::delete); &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Related to these changes are the cleanup and deprecation of many common operations. For example, imagine a scenario where you used both &lt;code&gt;withName()&lt;/code&gt; and a resource to perform an operation:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;client.configMaps().withName("x").replace(configMap); &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;This was potentially confusing in that there was an extra check to make sure that the name specified in &lt;code&gt;withName()&lt;/code&gt; matched the name of the &lt;code&gt;KubernetesResource&lt;/code&gt; passed into &lt;code&gt;replace()&lt;/code&gt;. With 6.0, you should instead perform the operations on the resource:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;// if you need a specific resource type client.configMaps().resource(configMap).replace(); // or if it can be a general Resource client.resource(configMap).replace(); &lt;/code&gt;&lt;/pre&gt; &lt;h2&gt;API refinements&lt;/h2&gt; &lt;p&gt;The 6.0 update has gone went beyond simply adding a few new things into the domain-specific language (DSL). The DSL has now been split from the implementation and has been cleaned out of anything that seemed unnecessary.&lt;/p&gt; &lt;p&gt;The 5.x client and prior versions had the primary API and implementation as a single &lt;code&gt;kubernetes-client&lt;/code&gt; module/jar. While convenient, it did not offer a clear separation of the API from internal classes, and exposed the consuming applications compile time classpath to additional dependencies (such as &lt;code&gt;OkHttp&lt;/code&gt;). A refactoring was undertaken to split the client into a separate API and implementation module. You may still continue to use just a reference to the &lt;code&gt;kubernetes-client&lt;/code&gt; if you wish, but you now also have the option of having a compile dependency on &lt;code&gt;kubernetes-client-api&lt;/code&gt; with a runtime dependency on &lt;code&gt;kubernetes-client&lt;/code&gt;.&lt;/p&gt; &lt;p&gt;This split also required us to make direct use of the default clients; &lt;code&gt;DefaultKubernetesClient&lt;/code&gt; and &lt;code&gt;DefaultOpenShiftClient&lt;/code&gt; have been deprecated. You should transition to using the &lt;code&gt;KubernetesClientBuilder&lt;/code&gt; instead, which you will be required to use if you have just the API module as a compile time dependency.&lt;/p&gt; &lt;p&gt;This refactoring allowed us to clean up some of the details of how the client extensions are implemented. They now only have a compile dependency on the &lt;code&gt;kubernetes-client-api&lt;/code&gt;, so you may notice a few changes if you use or further extend an extension such as &lt;a href="https://developers.redhat.com/topics/camel-k"&gt;Camel K&lt;/a&gt;, Istio, cert-manager, etc.&lt;/p&gt; &lt;p&gt;Finally, we took this opportunity to remove or collapse a lot of the interfaces that were used to make up the DSL. Most users, who are using fluent style calls, won't notice these changes as the operations are still there. However, if you created an intermediate variable at some point in the method chain, that particular class may no longer exist; for example, &lt;code&gt;EditReplacePatchDeleteble&lt;/code&gt; is no more. In that case, you'll have to update the type or use &lt;code&gt;var&lt;/code&gt; instead.&lt;/p&gt; &lt;h2&gt;Kubernetes testing improvements&lt;/h2&gt; &lt;p&gt;The integration testing utilities used by the Fabric8 project were refined and exposed for general use as a JUnit 5 extension in a new &lt;code&gt;kubernetes-junit-jupiter artifact&lt;/code&gt;. The new module offers a highly declarative set of annotations that you can use to simplify your project's test setup and execution against an actual Kuberentes cluster.&lt;/p&gt; &lt;p&gt;As described in issued &lt;a href="https://github.com/fabric8io/kubernetes-client/issues/4054"&gt;#4054&lt;/a&gt;, this module allows you to configure your tests like so:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;@KubernetesTest @LoadKubernetesManifests("/test-data.yml") @RequireK8sSupport(io.fabric8.knative.serving.v1.Service.class) // Optionally require support for a resource (test env should be reliable) @RequireK8sVersionAtLeast(majorVersion = 1, minorVersion = 16) // Optionally require a specific K8s version class MyTest { KubernetesClient client; // … } &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The extension takes care of creating a temporary namespace and injecting a &lt;code&gt;KubernetesClient&lt;/code&gt; instance preconfigured to use that namespace. In addition, the new extension provides an annotation to load and delete Kubernetes manifests before and after the test suite execution, along with two annotations to restrict the test execution to specific cluster versions, or support for specific Kubernetes resources.&lt;/p&gt; &lt;p&gt;Unit testing using the Kubernetes Mock server was also improved:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;You no longer need extension-specific modules such as &lt;code&gt;tekton-tests&lt;/code&gt;. Instead, you may directly reference the client type you need as a member variable. The appropriate instance will be initialized:&lt;/li&gt; &lt;/ul&gt; &lt;pre&gt;&lt;code&gt;@EnableKubernetesMockClient Class MyTest { TektonClient client; // … } &lt;/code&gt;&lt;/pre&gt; &lt;ul&gt; &lt;li&gt;&lt;strong&gt;Issue &lt;a href="https://github.com/fabric8io/kubernetes-client/issues/3966"&gt;#3966&lt;/a&gt;:&lt;/strong&gt; The &lt;code&gt;KubernetesMockServer&lt;/code&gt; has new methods— &lt;code&gt;reset()&lt;/code&gt; and &lt;code&gt;unsupported()&lt;/code&gt;— to reset its state and control what APIs are unsupported. The &lt;code&gt;reset()&lt;/code&gt; method is especially useful in crud mode to quickly clean out the mock server resource state in between tests.&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Issue &lt;a href="https://github.com/fabric8io/kubernetes-client/issues/3758"&gt;#3758&lt;/a&gt;:&lt;/strong&gt; &lt;code&gt;VersionInfo&lt;/code&gt; in &lt;code&gt;KubernetesMockServer&lt;/code&gt; can be overridden.&lt;/li&gt; &lt;/ul&gt; &lt;h2&gt;Other improvements&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;p&gt;&lt;strong&gt;Issue &lt;a href="https://github.com/fabric8io/kubernetes-client/issues/3334"&gt;#3334&lt;/a&gt;:&lt;/strong&gt; Added basic support for server-side apply: &lt;code&gt;patch(PatchContext.of(PatchType.SERVER_SIDE_APPLY), service)&lt;/code&gt;.&lt;/p&gt;&lt;/li&gt; &lt;li&gt;&lt;p&gt;&lt;strong&gt;Issue &lt;a href="https://github.com/fabric8io/kubernetes-client/issues/3625"&gt;#3625&lt;/a&gt;:&lt;/strong&gt; Added default maps in generated models, mostly to prevent the need for null checks on things like annotations and labels.&lt;/p&gt;&lt;/li&gt; &lt;li&gt;&lt;p&gt;Informer improvements:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;strong&gt;Issue &lt;a href="https://github.com/fabric8io/kubernetes-client/issues/3968"&gt;#3968&lt;/a&gt;:&lt;/strong&gt; &lt;code&gt;SharedIndexInformer.initialState&lt;/code&gt; can be used to set the store state before the informer starts.&lt;/li&gt; &lt;li&gt;&lt;code&gt;SharedIndexInformer&lt;/code&gt; allows for the addition and removal of indexes even after starting, and you can remove the default namespace index if you wish.&lt;/li&gt; &lt;li&gt;&lt;code&gt;Store.getKey()&lt;/code&gt; can be used rather than directly referencing static cache functions.&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Issues &lt;a href="https://github.com/fabric8io/kubernetes-client/issues/3472"&gt;#3472&lt;/a&gt; and &lt;a href="https://github.com/fabric8io/kubernetes-client/issues/3587"&gt;#3587&lt;/a&gt;:&lt;/strong&gt; Customization has been opened up for the &lt;code&gt;Informer&lt;/code&gt; store/cache key function and the way in which state is stored. See &lt;code&gt;BasicItemStore&lt;/code&gt;, &lt;code&gt;ReducedStateItemStore&lt;/code&gt;, and the &lt;code&gt;SharedIndexInformer.itemStore()&lt;/code&gt; function.&lt;/li&gt; &lt;/ul&gt;&lt;/li&gt; &lt;li&gt;&lt;p&gt;&lt;strong&gt;Issue &lt;a href="https://github.com/fabric8io/kubernetes-client/issues/3922"&gt;#3922&lt;/a&gt;:&lt;/strong&gt; Added &lt;code&gt;Client.supports()&lt;/code&gt; and &lt;code&gt;Client.hasApiGroup()&lt;/code&gt; methods for API server metadata introspection.&lt;/p&gt;&lt;/li&gt; &lt;/ul&gt; &lt;h1&gt;Deprecations and other important changes&lt;/h1&gt; &lt;p&gt;Since this is a major release there was quite a bit of legacy removed or deprecated, and there are various breaking changes. This section will cover some of the highlights, but please see the &lt;a href="https://raw.githubusercontent.com/fabric8io/kubernetes-client/6.0/doc/MIGRATION-v6.md"&gt;migration guide&lt;/a&gt; for a full list.&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;p&gt;To match the behavior of &lt;code&gt;kubectl&lt;/code&gt;, the client will now consider any call to &lt;code&gt;inNamespace&lt;/code&gt; as the namespace to use regardless of what is on a passed in item. Only if the client is left at the default namespace or a call has been made to &lt;code&gt;inAnyNamespace&lt;/code&gt; will the item namespace be used. This applies to all calls to &lt;code&gt;inNamespace&lt;/code&gt; at the client, operation, or resource level, and for all operations (load, create, delete, withItem, etc.).&lt;/p&gt;&lt;/li&gt; &lt;li&gt;&lt;p&gt;The backwards compatibility interceptor is now &lt;strong&gt;disabled&lt;/strong&gt; by default.&lt;/p&gt;&lt;/li&gt; &lt;li&gt;&lt;p&gt;The &lt;code&gt;apiVersion&lt;/code&gt; on a resource being deserialized is now required.&lt;/p&gt;&lt;/li&gt; &lt;li&gt;&lt;p&gt;Deleting a collection is now implemented using a single delete call, rather than for each item. When the collection is namespaced and &lt;code&gt;inAnyNamespace&lt;/code&gt; is used, a call will be made to first determine the affected namespaces, and then a collection delete issued against each namespace. The result of the delete calls will be a list of &lt;code&gt;StatusDetails&lt;/code&gt; rather than a &lt;code&gt;boolean&lt;/code&gt; value. A best effort is made to process the response from the server to populate the items that are deleted. This information is generally useful if you wish to implement some kind of blocking delete behavior—that is, if you want to ensure the returned resources (based upon a matching UID) have been deleted.&lt;/p&gt;&lt;/li&gt; &lt;li&gt;&lt;p&gt;&lt;code&gt;delete(List&lt;T&gt;)&lt;/code&gt; and &lt;code&gt;delete(T[])&lt;/code&gt; returning &lt;code&gt;boolean&lt;/code&gt; have been deprecated. They will always return &lt;code&gt;TRUE&lt;/code&gt;, and 404s on individual items will simply be ignored.&lt;/p&gt;&lt;/li&gt; &lt;li&gt;&lt;p&gt;&lt;code&gt;Client.isAdaptable()&lt;/code&gt; and &lt;code&gt;Client.adapt()&lt;/code&gt; will check first if the existing client is an instance of the desired type. &lt;code&gt;Client.adapt()&lt;/code&gt; will no longer perform the &lt;code&gt;isAdaptable()&lt;/code&gt; check—that is, you may freely adapt from one client to another as long as the extension exists. If you need to make a specific check of support, please use the &lt;code&gt;Client.supports()&lt;/code&gt; method.&lt;/p&gt;&lt;/li&gt; &lt;li&gt;&lt;p&gt;&lt;code&gt;Evictable.evict()&lt;/code&gt; will throw an exception rather than returning &lt;code&gt;FALSE&lt;/code&gt; if the pod is not found. This ensures that &lt;code&gt;FALSE&lt;/code&gt; strictly means that the eviction failed.&lt;/p&gt;&lt;/li&gt; &lt;li&gt;&lt;p&gt;The usage of piped streams is no longer supported—they make assumptions about reading and writing threads, which the client no longer honors. They should not be passed into the methods accepting &lt;code&gt;InputStreams&lt;/code&gt; and &lt;code&gt;OutputStreams&lt;/code&gt;.&lt;br /&gt; &lt;code&gt;ContainerResource.writingInput(PipedOutputStream in)&lt;/code&gt; and &lt;code&gt;readingXXX(PipedInputStream out)&lt;/code&gt; have been removed—use the redirecting methods instead.&lt;/p&gt;&lt;/li&gt; &lt;li&gt;&lt;p&gt;&lt;code&gt;TtyExecErrorChannelable&lt;/code&gt; methods have been deprecated in favor of &lt;code&gt;ExecWatch.exitCode()&lt;/code&gt; and &lt;code&gt;ExecListener.onExit()&lt;/code&gt;.&lt;br /&gt; &lt;code&gt;ContainerResource.readingInput(InputStream in)&lt;/code&gt; has been deprecated—use &lt;code&gt;redirectingInput()&lt;/code&gt; instead.&lt;/p&gt;&lt;/li&gt; &lt;/ul&gt; &lt;h1&gt;Learn more about Fabric8&lt;/h1&gt; &lt;p&gt;Fabric8's development team consists mostly of Java developers, so a Java developer's perspective heavily influences this client. If you want to work with us, please don't hesitate to join our community. There are a few ways to get involved with the development of the &lt;a href="https://github.com/fabric8io/kubernetes-client"&gt;Fabric8 Kubernetes Java client&lt;/a&gt;:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Create &lt;a href="https://github.com/fabric8io/kubernetes-client/issues"&gt;GitHub issues&lt;/a&gt; to let us know when features don't work as expected.&lt;/li&gt; &lt;li&gt;Participate in the &lt;a href="https://github.com/fabric8io/kubernetes-client/discussions"&gt;Fabric8 Kubernetes Client GitHub discussions&lt;/a&gt;.&lt;/li&gt; &lt;li&gt;Send &lt;a href="https://github.com/fabric8io/kubernetes-client/pulls"&gt;pull requests&lt;/a&gt; for bug fixes and enhancements.&lt;/li&gt; &lt;li&gt;Chat with us on the Fabric8 Kubernetes Java client &lt;a href="https://gitter.im/fabric8io/kubernetes-client"&gt;Gitter channel&lt;/a&gt;.&lt;/li&gt; &lt;li&gt;Ask Fabric8 related questions on &lt;a href="https://stackoverflow.com/questions/tagged/fabric8"&gt;StackOverflow&lt;/a&gt;.&lt;/li&gt; &lt;li&gt;Follow us on &lt;a href="https://twitter.com/fabric8io/"&gt;Twitter&lt;/a&gt;.&lt;/li&gt; &lt;/ul&gt; The post &lt;a href="https://developers.redhat.com/articles/2022/07/15/new-http-clients-java-generator-and-more-fabric8-600" title="New HTTP clients, a Java generator, and more in Fabric8 6.0.0"&gt;New HTTP clients, a Java generator, and more in Fabric8 6.0.0&lt;/a&gt; appeared first on &lt;a href="https://developers.redhat.com/blog" title="Red Hat Developer"&gt;Red Hat Developer&lt;/a&gt;. &lt;br /&gt;&lt;br /&gt;</summary><dc:creator>Steven Hawkins</dc:creator><dc:date>2022-07-15T07:00:00Z</dc:date></entry><entry><title type="html">How to select the "right" service with Stork?</title><link rel="alternate" href="https://quarkus.io/blog/stork-load-balancing/" /><author><name>Clement Escoffier</name></author><id>https://quarkus.io/blog/stork-load-balancing/</id><updated>2022-07-15T00:00:00Z</updated><content type="html">The essence of distributed systems resides in the interaction between services. In modern architectures, you often have multiple instances of your service to share the load or improve the resilience by redundancy. But, when you have all these instances, how do you select the best one? That’s where Stork helps....</content><dc:creator>Clement Escoffier</dc:creator></entry><entry><title type="html">Getting started with JSF 4.0 on WildFly 27</title><link rel="alternate" href="http://www.mastertheboss.com/java-ee/jsf/getting-started-with-jsf-4-0-on-wildfly-27/" /><author><name>F.Marchioni</name></author><id>http://www.mastertheboss.com/java-ee/jsf/getting-started-with-jsf-4-0-on-wildfly-27/</id><updated>2022-07-14T16:40:00Z</updated><content type="html">This article contains a preview of Jakarta Faces 4.0 which is an MVC framework for building user interface with Jakarta EE 10. To get started with Jakarta EE 10, you need to download the latest release of WildFly 27 which you can use to preview Jakarta EE 10 features. At the time of writing, the ... The post appeared first on .</content><dc:creator>F.Marchioni</dc:creator></entry><entry><title type="html">Infinispan 14.0.0.Dev04</title><link rel="alternate" href="https://infinispan.org/blog/2022/07/14/infinispan-14" /><author><name>William Burns</name></author><id>https://infinispan.org/blog/2022/07/14/infinispan-14</id><updated>2022-07-14T12:00:00Z</updated><content type="html">Dear Infinispan community, Infinispan 14 development release 04 is here! We are nearing the final release of Infinispan 14 Final, so we want to share a preview of what’s coming. HOTROD 4.0 PROTOCOL With the addition of the new API that was released in the previous Dev03 build of Infinispan we have had to update the HotRod protocol to satisfy the requirements of that API. The new protocol changes many of the operations to return additional information to include entry metadata as well as adding new header information to support the OpenTelemetry feature described below. OPENTELEMETRY Support OpenTelemetry tracing, for tracing cache operations executed by the Infinispan server, correlated with client requests (using both Hot Rod and REST APIs). Look out for a separate blog post describing this is in more detail later! REST ENDPOINT New distribution endpoint to provide exposing the data distribution information about the node and cluster. Includes node name, number of entries and total number of entries in the cluster RESP SERVER CONNECTOR The RESP connector is now exposed by default on the single port with the other protocols. If not explicitly configured a Replicated cache is used for its cache. IOURING SERVER COMPATIBILITY Our server can now utilize IOUring for its network socket connections. This requires a compatible Linux kernel to work properly. This can be enabled by setting the JVM property infinispan.server.channel.iouring to true. COMMAND LINE INTERFACE It is now possible to access the entry value information for data in the cache. Previously only the key information was available. MULTIMAP DUPLICATES The Multimap API has been enhanced to now support duplicate values for a given key. This is an optional configuration as you can still allow only distinct values for a given key. For example, your data may be A = [1,2,3,3,5] when duplicates are allowed. SIZE COMMAND OPTIMIZATIONS Size command has received some optimizations to increase performance under certain circumstances. This includes cases of shared stores and not having expiration for data. DOCUMENTATION As always, the Infinispan team hope you find the documentation useful and complete. We’d love to hear from you and really value feedback from our community. If you think something is missing from the docs or spot a correction, please get in touch and we’ll get on it straight away. RELEASE NOTES You can look at the to see what has changed. Get them from our .</content><dc:creator>William Burns</dc:creator></entry><entry><title>Kafka Monthly Digest: June 2022</title><link rel="alternate" href="https://developers.redhat.com/articles/2022/07/14/kafka-monthly-digest-june-2022" /><author><name>Mickael Maison</name></author><id>83d0e7ab-3fe2-49d8-af94-1f19466b1b5e</id><updated>2022-07-14T07:00:00Z</updated><published>2022-07-14T07:00:00Z</published><summary type="html">&lt;p&gt;This 53rd edition of the Kafka Monthly Digest covers what happened in the &lt;a href="https://kafka.apache.org/"&gt;Apache Kafka&lt;/a&gt; community in June 2022.&lt;/p&gt; &lt;p&gt;For last month’s digest, see &lt;a href="https://developers.redhat.com/articles/2022/06/06/kafka-monthly-digest-may-2022"&gt;Kafka Monthly Digest: May 2022&lt;/a&gt;.&lt;/p&gt; &lt;h2&gt;Releases&lt;/h2&gt; &lt;p&gt;There is currently one release in progress: 3.3.0.&lt;/p&gt; &lt;h3&gt;3.3.0&lt;/h3&gt; &lt;p&gt;The release process for 3.3.0 continued. KIP freeze happened on June 15, and feature freeze happened on July 6. You can find the &lt;a href="https://cwiki.apache.org/confluence/display/KAFKA/Release+Plan+3.3.0"&gt;release plan&lt;/a&gt; in the wiki.&lt;/p&gt; &lt;h2&gt;Kafka Improvement Proposals&lt;/h2&gt; &lt;p&gt;Last month, the community submitted 4 &lt;a href="https://cwiki.apache.org/confluence/display/KAFKA/Kafka+Improvement+Proposals"&gt;KIPs&lt;/a&gt; (KIP-847 to KIP-850). I'll highlight a few of them:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;p&gt;&lt;a href="https://cwiki.apache.org/confluence/display/KAFKA/KIP-847%3A+Add+ProducerIdCount+metrics"&gt;&lt;strong&gt;KIP-847: Add ProducerCount metrics&lt;/strong&gt;&lt;/a&gt;: This KIP proposes adding new metrics to track how many idempotent and transactional producers are connected to each broker. For each idempotent or transactional producer connected, brokers keep in memory some metadata about it. The goal is to improve observability and help diagnose whether there may be too many producers connected.&lt;/p&gt;&lt;/li&gt; &lt;li&gt;&lt;p&gt;&lt;a href="https://cwiki.apache.org/confluence/display/KAFKA/KIP-848%3A+The+Next+Generation+of+the+Consumer+Rebalance+Protocol"&gt;&lt;strong&gt;KIP-848: The Next Generation of the Consumer Rebalance Protocol&lt;/strong&gt;&lt;/a&gt;: The Kafka group membership protocol allows distributing resources amongst client instances. It is used by consumers when they are in groups, but also by Connect and Streams. While this protocol is very flexible, over the years a few pain points have been identified. This KIP proposes significantly updating this protocol to make rebalances lightweight and simplify troubleshooting by moving most of the logic to the server side.&lt;/p&gt;&lt;/li&gt; &lt;li&gt;&lt;p&gt;&lt;a href="https://cwiki.apache.org/confluence/display/KAFKA/KIP-849%3A+Expose+logdirs+total+and+usable+space+via+kafka-log-dirs.sh"&gt;&lt;strong&gt;KIP-849: Expose logdirs total and usable space via kafka-log-dirs.sh&lt;/strong&gt;&lt;/a&gt;: In Kafka 3.2, &lt;a href="https://cwiki.apache.org/confluence/display/KAFKA/KIP-827%3A+Expose+logdirs+total+and+usable+space+via+Kafka+API"&gt;KIP-827&lt;/a&gt; exposed the size of usable and total space of log directories via the Admin API. This KIP aims at updating &lt;code&gt;kafka-log-dirs.sh&lt;/code&gt; to include these values in its output so administrators can easily access them.&lt;/p&gt;&lt;/li&gt; &lt;/ul&gt; &lt;h2&gt;Community releases&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;p&gt;&lt;a href="https://github.com/edenhill/librdkafka/releases/tag/v1.9.0"&gt;Librdkafka 1.9.0&lt;/a&gt;. Librdkafka is a Kafka client in &lt;a href="https://developers.redhat.com/topics/c"&gt;C/C++&lt;/a&gt;. This new release adds support for OAuthbearer OIDC and admin APIs for managing ACLs. As always, it also brings in many improvements and bug fixes.&lt;/p&gt;&lt;/li&gt; &lt;li&gt;&lt;p&gt;&lt;a href="https://github.com/tulios/kafkajs/releases/tag/v2.1.0"&gt;kafkajs 2.1&lt;/a&gt;: Kafkajs is a pure &lt;a href="https://developers.redhat.com/topics/javascript"&gt;JavaScript&lt;/a&gt; Kafka client for &lt;a href="https://developers.redhat.com/topics/nodejs"&gt;Node.js&lt;/a&gt;. Users can now pause and resume consuming partitions directly from from the &lt;code&gt;eachBatch&lt;/code&gt;/&lt;code&gt;eachMessage&lt;/code&gt; handlers. This release also contains some important bug fixes.&lt;/p&gt;&lt;/li&gt; &lt;/ul&gt; &lt;h2&gt;Blogs&lt;/h2&gt; &lt;p&gt;I selected some interesting blog posts and articles that were published last month:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;a href="https://distributedsystemsmadeeasy.medium.com/high-watermark-distributed-design-patterns-c1f3330d8129"&gt;High watermark: Distributed design patterns&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://medium.com/wise-engineering/rack-awareness-in-kafka-streams-448d7e5225a3"&gt;Rack awareness in Kafka Streams&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://medium.com/shippeo-tech-blog/debezium-to-snowflake-lessons-learned-building-data-replication-in-production-a5430a9fe85b"&gt;Debezium to Snowflake: Lessons learned building data replication in production&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;To learn more about Kafka, visit &lt;a href="https://developers.redhat.com/topics/kafka-kubernetes"&gt;Red Hat Developer's Apache Kafka topic page&lt;/a&gt;.&lt;/p&gt; The post &lt;a href="https://developers.redhat.com/articles/2022/07/14/kafka-monthly-digest-june-2022" title="Kafka Monthly Digest: June 2022"&gt;Kafka Monthly Digest: June 2022&lt;/a&gt; appeared first on &lt;a href="https://developers.redhat.com/blog" title="Red Hat Developer"&gt;Red Hat Developer&lt;/a&gt;. &lt;br /&gt;&lt;br /&gt;</summary><dc:creator>Mickael Maison</dc:creator><dc:date>2022-07-14T07:00:00Z</dc:date></entry><entry><title type="html">This Week in JBoss - 15 July 2022</title><link rel="alternate" href="https://www.jboss.org/posts/weekly-2022-07-14.html" /><category term="quarkus" /><category term="kubernetes" /><category term="java" /><category term="infinispan" /><category term="jakarta ee" /><category term="wildfly" /><category term="ansible" /><category term="azure app service" /><author><name>Francesco Marchioni</name><uri>https://www.jboss.org/people/francesco-marchioni</uri><email>do-not-reply@jboss.com</email></author><id>https://www.jboss.org/posts/weekly-2022-07-14.html</id><updated>2022-07-14T00:00:00Z</updated><content type="html">&lt;article class="" data-tags="quarkus, kubernetes, java, infinispan, jakarta ee, wildfly, ansible, azure app service"&gt; &lt;h1&gt;This Week in JBoss - 15 July 2022&lt;/h1&gt; &lt;p class="preamble"&gt;&lt;/p&gt;&lt;p&gt;Happy Friday, everyone!&lt;/p&gt; &lt;p&gt;Here is another edition of the JBoss Editorial with exciting news and updates from your JBoss communities.&lt;/p&gt;&lt;p&gt;&lt;/p&gt; &lt;div class="sect1"&gt; &lt;h2 id="_release_roundup"&gt;Release roundup&lt;/h2&gt; &lt;div class="sectionbody"&gt; &lt;p&gt;Here are the most recent releases for this edition:&lt;/p&gt; &lt;div class="ulist square"&gt; &lt;ul class="square"&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://quarkus.io/blog/quarkus-2-10-2-final-released/"&gt;Quarkus 2.10.2&lt;/a&gt; - There is a new maintenance release with a new round of bugfixes and documentation improvements. Besides, there is a bump version for some packages (JReleaser/Keycloak). This should be a safe upgrade upgrade for anyone already using 2.10. Check here the full &lt;a href="https://github.com/quarkusio/quarkus/releases/tag/2.10.2.Final"&gt;change log&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://github.com/kiegroup/kogito-images/releases"&gt;Kogito 1.24.0&lt;/a&gt; - We are glad to announce that the Kogito 1.24.0 release is now available!.&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://camel.apache.org/download/"&gt;Camel 3.18.0&lt;/a&gt; - Apache Camel 3.18.0 it’s available. A new LTS release with 117 new features, improvements and fixes. Supports Java 11 and 17. New releases available also for the other Apache Camel Streams (Camel/K, Kamelets, Camel Kafka Connector, Camel Quarkus )&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://www.wildfly.org/downloads/"&gt;WildFly 27 Alpha 2&lt;/a&gt; - A new Alpha release of WildFly 27 (Alpha 2) is available if you want a preview of Jakarta EE 10 features which will be fully available with WildFly 27&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="sect1"&gt; &lt;h2 id="_deploy_jboss_eap_on_microsoft_azure_red_hat_openshift"&gt;Deploy JBoss EAP on Microsoft Azure Red Hat OpenShift&lt;/h2&gt; &lt;div class="sectionbody"&gt; &lt;p&gt;&lt;a href="https://developers.redhat.com/articles/2022/07/06/deploy-jboss-eap-microsoft-azure-red-hat-openshift"&gt;Deploy JBoss EAP on Microsoft Azure Red Hat OpenShift&lt;/a&gt;, by Philip Hayes&lt;/p&gt; &lt;p&gt;There’s a strong demand for cloud-based JBoss EAP options from our customers. This article outlines the benefits of deploying Red Hat JBoss Enterprise Application Platform (EAP) on Red Hat OpenShift and Microsoft Azure.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="sect1"&gt; &lt;h2 id="_the_road_to_jboss_eap_8"&gt;The Road to JBoss EAP 8&lt;/h2&gt; &lt;div class="sectionbody"&gt; &lt;p&gt;&lt;a href="https://developers.redhat.com/articles/2022/06/24/road-jboss-eap-8"&gt;The Road to JBoss EAP 8&lt;/a&gt;, by James Falkner&lt;/p&gt; &lt;p&gt;Find out how Jakarta EE specifications have evolved since Red Hat JBoss Enterprise Application Platform 7 and what to look forward to in JBoss EAP 8.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="sect1"&gt; &lt;h2 id="_a_first_sip_of_jakarta_faces_4_0_on_wildfly_27"&gt;A first sip of Jakarta Faces 4.0 on WildFly 27&lt;/h2&gt; &lt;div class="sectionbody"&gt; &lt;p&gt;&lt;a href="http://www.mastertheboss.com/java-ee/jsf/getting-started-with-jsf-4-0-on-wildfly-27/"&gt;Getting started with Jakarta Faces 4.0&lt;/a&gt;, by Francesco Marchioni&lt;/p&gt; &lt;p&gt;Jakarta EE 10 is almost there! Today we will have a look at what is new in Jakarta Faces 4.0 which is available in the Alpha2 version of WildFly 27.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="sect1"&gt; &lt;h2 id="_camel_k_operations_monitoring"&gt;Camel K Operations: Monitoring&lt;/h2&gt; &lt;div class="sectionbody"&gt; &lt;p&gt;&lt;a href="https://camel.apache.org/blog/2022/07/camel-k-monitoring-ops/"&gt;How to monitor a Camel K Integration&lt;/a&gt;, by Pasquale Congiusti&lt;/p&gt; &lt;p&gt;How to monitor a Camel K Integration?. Fortunately, Camel-K has all it takes to let you manage this operation as smooth as possible. This article walks through it.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="sect1"&gt; &lt;h2 id="_youtube_video_elytron_filesystem_realm_encryption"&gt;Youtube video: Elytron Filesystem Realm Encryption&lt;/h2&gt; &lt;div class="sectionbody"&gt; &lt;p&gt;&lt;a href="https://www.youtube.com/watch?v=1K92tit2uCk"&gt;Elytron Filesystem Realm Encryption&lt;/a&gt;, by Ashpan Raskar&lt;/p&gt; &lt;p&gt;Finally, from WildFly’s youtube channel check this video by Jeff Meslin to learn how to encrypt an Elytron Filesystem Realm and how to convert old filesystem realms to newly encrypted filesystem realms.&lt;/p&gt; &lt;p&gt;&lt;em&gt;That’s all folks! Please join us again in two weeks for another round of our JBoss editorial!&lt;/em&gt;&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="author"&gt; &lt;pfe-avatar pfe-shape="circle" pfe-pattern="squares" pfe-src="/img/people/francesco-marchioni.png"&gt;&lt;/pfe-avatar&gt; &lt;span&gt;Francesco Marchioni&lt;/span&gt; &lt;/div&gt;&lt;/article&gt;</content><dc:creator>Francesco Marchioni</dc:creator></entry></feed>
